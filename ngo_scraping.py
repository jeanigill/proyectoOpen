# -*- coding: utf-8 -*-
"""NGO_Scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RfAcOQeOkWMz0ztk1o2z4g8Awin6w2iJ

NGO SAECA - ELECTRODOMESTICOS
"""

# Commented out IPython magic to ensure Python compatibility.
#Importar las librerias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import re
import time
from datetime import datetime
import matplotlib.dates as mdates
import matplotlib.ticker as ticker
from urllib.request import urlopen
from bs4 import BeautifulSoup
import requests

# url del producto
URL = 'https://ngosaeca.com.py/buscar/cocina%20a%20gas'
# request header
# para que stock no nos detecte como un robot
headers = {
'authority': 'ngosaeca.com.py',
'pragma': 'no-cache',
'cache-control': 'no-cache',
'dnt': '1',
'upgrade-insecure-requests': '1',
'user-agent': 'User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36',
'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
'sec-fetch-site': 'none',
'sec-fetch-mode': 'navigate',
'sec-fetch-dest': 'document',
'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',
}

#Definir n√∫mero de paginas
no_pages = 4

# descargar la pagina
page = requests.get(URL, headers = headers)
# leer el contenido
soup = BeautifulSoup(page.content, 'html.parser')

#Funcion
def get_data(pageNo):
    headers = {
    'authority': 'ngosaeca.com.py',
    'pragma': 'no-cache',
    'cache-control': 'no-cache',
    'dnt': '1',
    'upgrade-insecure-requests': '1',
    'user-agent': 'User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0',
    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
    'sec-fetch-site': 'none',
    'sec-fetch-mode': 'navigate',
    'sec-fetch-dest': 'document',
    'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',
    }
    stock = requests.get('https://ngosaeca.com.py/buscar/cocina%20a%20gas'+str(pageNo), headers=headers)
    content = stock.content
    soup = BeautifulSoup(content)
    alls = []

    #Identificar y recorrer las clases de producto y precio
    for d in soup.findAll('li', attrs={'class':'product'}):
        #print(d)
        name = d.find('h3', attrs={'class':'menu-item-first-letter-uppercase'})
        #print(n[0]['alt'])
        price = d.find('span', attrs={'class':'amount'})

        all1=[]

        if name is not None:
            #print(n[0]['alt'])
            all1.append(name.text)
        else:
            all1.append('0')  

        if price is not None:
            #print(price.text)
            all1.append(price.text)
        else:
            all1.append('0')
        alls.append(all1)
    return alls

#Listar y ordenar los datos en un df
results = []
for i in range(1, no_pages+1):
    results.append(get_data(i))
flatten = lambda l: [item for sublist in l for item in sublist]
df = pd.DataFrame(flatten(results),columns=['Name', 'Price'])
df.to_csv('bristol_products.csv', index=False, encoding='utf-8')

df